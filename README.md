
---

````markdown
# ğŸ§  LangChain âœ¨ Streamlit Chatbot with Ollama Gemma (2B)

This project is a **minimal LLM chatbot interface** built with [LangChain](https://www.langchain.com/), [Streamlit](https://streamlit.io/), and [Ollama](https://ollama.com/).  
It demonstrates prompt templating, LangSmith tracing, and integrates the lightweight `gemma:2b` model locally using Ollama.

---

## ğŸ“º Demo

â–¶ï¸ **YouTube Walkthrough**: [Watch Here](https://www.youtube.com/watch?v=dQw4w9WgXcQ)  
<!-- Replace this link with your real YouTube video -->

---

## ğŸ§© Key Features

- âš™ï¸ **LangChain + Ollama** integration
- ğŸ¤– Uses local `gemma:2b` LLM via `Ollama`
- ğŸ§  Prompt Engineering with `ChatPromptTemplate`
- ğŸ“Š LangSmith Tracing for real-time chain visualization
- ğŸ’» Frontend: Streamlit-powered chat interface

---

## ğŸ“ Project Structure

```plaintext
.
â”œâ”€â”€ app.py              # Main Streamlit app
â”œâ”€â”€ .env                # Environment variables for LangChain
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md           # Project documentation
````

---

## ğŸ”§ Setup Instructions

### 1ï¸âƒ£ Clone the Repo

```bash
git clone https://github.com/yourusername/ollama-sample-genai-app.git
cd ollama-sample-genai-app
```

### 2ï¸âƒ£ Install Dependencies

Using `uv` or `pip`:

```bash
uv pip install -r requirements.txt
# OR
pip install -r requirements.txt
```

### 3ï¸âƒ£ Setup `.env`

Create a `.env` file in the root directory:

```env
LANGCHAIN_API_KEY= Get the key from langchain's official website
LANGCHAIN_PROJECT= Whatever you want to name the project
```

### 4ï¸âƒ£ Run Ollama Model

Ensure Ollama is installed and running:

```bash
ollama run gemma:2b
```

### 5ï¸âƒ£ Launch the App

```bash
streamlit run app.py
```

---

## ğŸ“¦ Dependencies

Listed in `requirements.txt`:

```
langchain
langchain_community
langchain-openai
python-dotenv
ipykernel
beautifulsoup4
faiss-cpu
streamlit
```

---

## ğŸ™‹â€â™‚ï¸ About Me

Iâ€™m a passionate Data Science & GenAI developer building end-to-end AI applications using **LangChain**, **MLOps**, and **LLMs**.

ğŸ“Œ Looking for roles in:
ğŸ§  AI / LLM Engineering â€¢ ğŸ“Š Data Science â€¢ âš™ï¸ MLOps â€¢ ğŸ§© GenAI R\&D

ğŸ”— [LinkedIn](https://www.linkedin.com/in/yourname)
ğŸŒ [Portfolio Website](https://yourwebsite.com)

---

## ğŸ What's Next?

* Add Memory, Tool usage, or Vector DB (e.g., FAISS)
* Convert to FastAPI + LangServe backend
* Deploy to GCP / Hugging Face Spaces / Streamlit Cloud

---

â­ If you like this project, give it a **star** and fork it to build your own!

```

---

âœ… Now just **replace these placeholders**:

- `https://www.youtube.com/watch?v=dQw4w9WgXcQ` â†’ Your actual YouTube demo link  
- `yourusername` â†’ Your GitHub username  
- `https://www.linkedin.com/in/yourname` â†’ Your LinkedIn profile  
- `https://yourwebsite.com` â†’ Your portfolio website (optional)

Let me know if you'd like help uploading to GitHub or generating a thumbnail too.
```
